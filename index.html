<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Performance study of HEP data analysis tools</title>
  <link rel="stylesheet" href="poster.css">
  <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1">
  <!-- Based on a poster template from https://github.com/cpitclaudel/academic-poster-template -->

  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link
    href="https://fonts.googleapis.com/css2?family=Fira+Sans+Condensed:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&amp;family=Ubuntu+Mono:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap"
    rel="stylesheet">

  <style type="text/css">
    html {
      font-size: 1.15rem
    }
  </style>
</head>

<body vocab="http://schema.org/" typeof="ScholarlyArticle">
  <header role="banner">
    <aside>
      <!-- <a href="https://github.com/cpitclaudel/academic-poster-template"><img src="logo.svg" alt="Tutorial logo"></a> -->
    </aside>
    <div>
      <h1 property="headline">Performance study of HEP data analysis tools</h1>
      <h2 property="alternativeHeadline">
        Project carried out at INFN-Sezione di Bari (June - August 2022) 
        as part of the DOE-INFN Summer Exchange Program 2022
      </h2>
      <address>
        <a property="author">Dung Hoang<sup>a</sup></a><a property="author">, Adriano Di Florio<sup>b, d</sup></a></a><a
          property="author">, Alexis Pompili<sup>b, c</sup></a></a><a property="author">, Umit Sozbilir<sup>b,
            c</sup></a></a><a property="author">, Vincenzo Mastrapasqua<sup>b, c</sup></a>
        <br /> <sup>a</sup><a property="sourceOrganization">Rhodes College,&nbsp</a><sup>b</sup><a
          property="sourceOrganization">INFN-Bari,&nbsp</a><sup>c</sup><a property="sourceOrganization">Università degli
          studi di Bari Aldo Moro,&nbsp</a><sup>d</sup><a property="sourceOrganization">Politecnico di Bari</a>
      </address>
      <span class="publication-info">
        <span property="publisher">Unpublished</span>,
        <time pubdate property="datePublished" datetime="2020-09-08">September 8, 2020</time>
      </span>
    </div>
    <aside>
      <!-- <a href="https://csail.mit.edu"><img style="background: white" src="csail.png" alt="MIT CSAIL Logo"></a> -->
    </aside>
  </header>

  <main property="articleBody">
    <article property="abstract">
      <header>
        <h3>Introduction</h3>
      </header>

      <p>
        The Python programming language has an enormous and rapidly growing ecosystem that supports the analysis and
        visualization of large datasets. Examples include Numpy (numerical computing), pandas (data manipulation),
        matplotlib (visualization), and tensorflow (machine learning). With the huge amount of data that HEP experiments
        produce, therefore, a complete HEP data analysis workflow in Python would provide great benefits. In this
        project, we explored different approaches to process data stored in ROOT files using Python libraries and
        frameworks. Specifically, we measured the performance of <strong>Uproot</strong>, a library for reading and
        writing ROOT files in pure Python and Numpy, and the Pythonized version of <strong>RDataFrame</strong>, a
        modern, high-level interface
        for the analysis
        of HEP data.
      </p>
    </article>

    <article property="abstract">
      <header>
        <h3>Data</h3>
      </header>

      <p>
        The ROOT files used in our measurements, which contain 457860912 events and take up more than 128GB of disk
        space in total, were taken from CMS Run 2 dataset.
      </p>

      <p>
        For reasons that will be specified later, we split the original data set into 128 files with approximately the
        same size.
      </p>
    </article>

    <article property="abstract">
      <header>
        <h3>Computing resources</h3>
      </header>

      <p>
        Measurements were run on three different machines on the ReCaS-Bari computing center:
      </p>

      <ol>
        <li>
          <strong>wn-gpu-8-3-22</strong> (256 CPUs, 2003 GB RAM)
        </li>
        <li>
          <strong>wn-1-8-9</strong> (64 CPUs, 251GB RAM)
        </li>
        <li>
          <strong>tesla04</strong> (32 CPUs, 251 GB RAM)
        </li>
      </ol>

      <p>
        For the first two machines, data could only be stored remotely on the computing cluster, while on
        <strong>tesla04</strong>, it
        was also possible to access the data on the local disk.
      </p>

    </article>

    <article property="abstract">
      <header>
        <h3>Analysis task</h3>
      </header>

      <p>
        With Uproot and RDataFrame, we measured the total runtime of the following operations:
      </p>

      <ol>
        <li>
          Accessing the TTree’s in the ROOT files.
        </li>
        <li>
          Applying specific filters (selection criteria) on the data to expose the signal of the B0s meson decaying into
          the J/psi meson (decaying into two muons) and the Phi meson (decaying into two tracks with Kaon mass
          assigned).
        </li>
        <li>
          Converting the TBranch containing the mass to a NumPy array.
        </li>
      </ol>

    </article>

    <article property="abstract">
      <header>
        <h3>Analysis task</h3>
      </header>


      <figure>
        <img src="plots/dist1.png">
      </figure>
      <figure>
        <img src="plots/dist2.png">
      </figure>

    </article>

    <article property="abstract">
      <header>
        <h3>Setup</h3>
      </header>

      <p>
        To take advantage of our multi-core computers, we adopted parallel processing in our measurement. In other
        words, instead of letting one CPU handle the whole dataset, we used multiple CPUs running in parallel to process
        pieces of data concurrently.
      </p>

    </article>

    <article property="abstract">
      <header>
        <h3>Uproot</h3>
      </header>

      <p>
        With Uproot, there isn’t a built-in option for implicit parallel processing. To enable parallelism, therefore,
        we manually created subprocesses with Python’s multiprocessing module. Since Uproot allows users to specify the
        number of events to be processed in each TTree, the smallest unit of data distributed to each subprocess is one
        event. As a result, the workload can always be divided equally among subprocesses.
      </p>

    </article>

    <article property="abstract">
      <header>
        <h3>RDataFrame</h3>
      </header>

      <p>
        RDataFrame, on the other hand, has a built-in option for implicit parallelism: EnableImplicitMT(). However, it
        appears to work inconsistently on different machines and different ROOT versions.
      </p>

      <figure>
        <img src="plots/implicitmt1.png">
      </figure>
      <figure>
        <img src="plots/implicitmt3.png">
      </figure>
      <figure>
        <img src="plots/implicitmt2.png">
      </figure>

    </article>

    <article property="abstract">
      <header>
        <h3>RDataFrame</h3>
      </header>

      <p>
        Alternatively, we followed the same approach mentioned above: explicitly creating subprocesses to handle pieces
        of data. Unlike Uproot,
        RDataFrame doesn’t provide the option to specify the number of events to be processed in each file, so the
        smallest unit of data distributed to each subprocess is one
        file. As a result, each subprocess will work on
        approximately the same number of files rather than the same number of events.
      </p>

      <p>
        To make it easier to distribute data evenly with RDataFrame, we split – by using Uproot – the original dataset
        into 128 files, each containing the
        same number of events. For a fair comparison, we used these files as input for both Uproot and RDataFrame.
      </p>

    </article>

    <article property="abstract">
      <header>
        <h3>Results</h3>
      </header>

      <figure>
        <img src="plots/rvp1.png">
      </figure>
      <figure>
        <img src="plots/rvp2.png">
      </figure>
      <figure>
        <img src="plots/rvp3.png">
      </figure>

    </article>

    <article property="abstract">
      <header>
        <h3>Results</h3>
      </header>

      <figure>
        <img src="plots/svp1.png">
      </figure>
      <figure>
        <img src="plots/svp2.png">
      </figure>
      <figure>
        <img src="plots/svp3.png">
      </figure>

    </article>

    <article property="abstract">
      <header>
        <h3>Results</h3>
      </header>

      <figure>
        <img src="plots/rvs1.png">
      </figure>
      <figure>
        <img src="plots/rvs2.png">
      </figure>
      <figure>
        <img src="plots/rvs3.png">
      </figure>

    </article>

    <article property="abstract">
      <header>
        <h3>Results</h3>
      </header>

      <figure>
        <img src="plots/localvsremote1.png">
      </figure>
      <figure>
        <img src="plots/localvsremote2.png">
      </figure>

    </article>

    <article property="abstract">
      <header>
        <h3>Conclusion</h3>
      </header>

      <p>
        By enabling parallelism, we effectively optimized the performance of both Uproot and RDataFrame. While Uproot
        ran faster at fewer processes, RDataFrame got better performance as the number of processes increased. This may
        suggest that on machines with a lot of CPUs, it is more beneficial to use the latter. However, we must keep in
        mind that RDataFrame was able to reach such a great performance because the original dataset was divided into
        many small files with the same number of events. In real-life situations, such condition is not guaranteed, so
        Uproot may still be the better choice.
      </p>

    </article>

    <!-- <figure style="flex-grow: 9999999">
      <img style="width: 70%" src="logo.svg" alt="Project logo" />
      <figcaption>A stand-alone figure to fill the remaining space.</figcaption>
    </figure> -->
  </main>

  <!-- <footer>
    <address class="monospace"> <a
        href="https://github.com/cpitclaudel/academic-poster-template">https://github.com/cpitclaudel/academic-poster-template</a>
    </address>
    <address class="monospace"> clement.pitclaudel@live.com
    </address>
    <span class="credits">
      Based on an <a href="https://github.com/cpitclaudel/academic-poster-template">open poster template</a>.
    </span>
  </footer> -->
</body>

</html>